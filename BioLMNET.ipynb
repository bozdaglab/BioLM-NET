{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f46b7-f788-499d-b014-7c28905eeff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Lambda, Dense, Dropout, Input, concatenate, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras import backend as K, regularizers, initializers\n",
    "from tensorflow.keras.initializers import LecunUniform, GlorotUniform\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from tqdm_joblib import tqdm_joblib\n",
    "from huggingface_hub import hf_hub_download\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e884e-58a5-434e-95df-0735956321b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "FNAME = \"embedding_associations_cell_type_tissue_drug_pathway_openai_large.parquet\"  \n",
    "parquet_path = hf_hub_download(\n",
    "    repo_id   = \"honicky/genept-composable-embeddings\",\n",
    "    filename  = FNAME,\n",
    "    repo_type = \"model\"\n",
    ")\n",
    "emb = pd.read_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d2523-d9a0-466f-bc58-8c815370e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene = pd.read_csv(Path(__file__).parent / \"Dataset\"/\"scTrioseq2\"/ \"Gene_Expression.csv\")\n",
    "df_dna = pd.read_csv(Path(__file__).parent / \"Dataset\"/\"scTrioseq2\"/ \"DNA_Methylation.csv\")\n",
    " \n",
    "true_label = pd.read_csv(Path(__file__).parent / \"Dataset\"/\"scTrioseq2\"/ \"label.csv\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "le.fit(true_label)\n",
    "y = le.transform(true_label)\n",
    "\n",
    "ge_genes = list(df_gene.columns)\n",
    "\n",
    "df_pdi = pd.read_csv(Path(__file__).parent / \"Dataset\"/\"PDI\"/ \"PDI.csv\",sep=',')\n",
    "df_ge_pdi = df_pdi[df_pdi.Target.isin(ge_genes)]\n",
    "unique_tfs = df_ge_pdi['TF'].unique()\n",
    "unique_targets = df_ge_pdi['Target'].unique()\n",
    "\n",
    "dna_genes =list(df_dna.columns) \n",
    "df_dna_pdi = df_pdi[df_pdi.Target.isin(dna_genes)]\n",
    "\n",
    "dna_unique_tfs = df_dna_pdi['TF'].unique()\n",
    "dna_unique_targets = df_dna_pdi['Target'].unique()\n",
    "\n",
    "df_ppi = pd.read_csv(Path(__file__).parent / \"Dataset\"/\"PPI\"/ \"PPI.csv\",sep=',')\n",
    "df_ppi = df_ppi.drop(['Unnamed: 0'], axis =1)\n",
    "df_ppi['combined_score'] = df_ppi['combined_score'] /1000\n",
    "threshold = df_ppi['combined_score'].quantile(0.9)\n",
    "df_ppi = df_ppi[df_ppi['combined_score'] >= threshold]\n",
    "df_ge_ppi = df_ppi[df_ppi['protein1'].isin(ge_genes) | df_ppi['protein2'].isin(ge_genes)]\n",
    "unique_protein1 = df_ge_ppi['protein1'].unique()\n",
    "unique_protein2 = df_ge_ppi['protein2'].unique()\n",
    "\n",
    "df_dna_ppi = df_ppi[df_ppi['protein1'].isin(dna_genes) | df_ppi['protein2'].isin(dna_genes)]\n",
    "dna_unique_protein1 = df_dna_ppi['protein1'].unique()\n",
    "dna_unique_protein2 = df_dna_ppi['protein2'].unique()\n",
    "\n",
    "ge_pdi_ppi_genes = list(set(unique_targets) | set(unique_protein2))\n",
    "dna_pdi_ppi_genes = list(set(dna_unique_targets) | set(dna_unique_protein2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e868db94-f1d2-413a-b36f-028cb0d7499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genept_gene_emb = emb.loc[emb.index.isin(ge_pdi_ppi_genes)]\n",
    "ge_pdi_ppi_genept = genept_gene_emb.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd04c7c-6119-4f60-836e-43d2c2060299",
   "metadata": {},
   "outputs": [],
   "source": [
    "genept_dna_emb = emb.loc[emb.index.isin(dna_pdi_ppi_genes)]\n",
    "dna_pdi_ppi_genept = genept_dna_emb.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537876a2-01e5-4a8f-92df-621469614756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ge_mask_matrix (extra_neurons):\n",
    "    de_gene_to_idx = {gene: i for i, gene in enumerate(ge_genes)}\n",
    "    target_to_idx = {target: j for j, target in enumerate(unique_targets)}\n",
    "    protein2_to_idx = {protein2: k for k, protein2 in enumerate(unique_protein2)}\n",
    "\n",
    "    pdi_mask_matrix = np.zeros((len(ge_genes), len(unique_targets)), dtype=int)\n",
    "\n",
    "    for _, row in df_ge_pdi.iterrows():\n",
    "        tfa = row[\"TF\"]\n",
    "        target = row[\"Target\"]\n",
    "        if tfa in de_gene_to_idx and target in target_to_idx:\n",
    "            tf_idx = de_gene_to_idx[tfa]\n",
    "            target_idx = target_to_idx[target]\n",
    "            pdi_mask_matrix[tf_idx, target_idx] = 1\n",
    "    \n",
    "    ppi_mask_matrix = np.zeros((len(ge_genes), len(unique_protein2)))\n",
    "\n",
    "    for _, row in df_ge_ppi.iterrows():\n",
    "        protein1 = row[\"protein1\"]\n",
    "        protein2 = row[\"protein2\"]\n",
    "        combined_score = row[\"combined_score\"]\n",
    "\n",
    "        if protein1 in de_gene_to_idx and protein2 in protein2_to_idx:\n",
    "            protein1_idx = de_gene_to_idx[protein1]\n",
    "            protein2_idx = protein2_to_idx[protein2]\n",
    "            ppi_mask_matrix[protein1_idx, protein2_idx] = combined_score \n",
    "            \n",
    "    pdi_mask_df=     pd.DataFrame(pdi_mask_matrix)\n",
    "    ppi_mask_df=     pd.DataFrame(ppi_mask_matrix)\n",
    "    pdi_mask_df.columns = unique_targets\n",
    "    ppi_mask_df.columns = unique_protein2\n",
    "    pdi_ppi_mask_df = pd.concat([pdi_mask_df, ppi_mask_df], axis=1)\n",
    "    pdi_ppi_mask_df = pdi_ppi_mask_df.loc[:, ~pdi_ppi_mask_df.columns.duplicated(keep='last')]\n",
    "    col_mask = pdi_ppi_mask_df.columns.isin(ge_pdi_ppi_genept)\n",
    "    sub_pdi_ppi_mask_df = pdi_ppi_mask_df.loc[:, col_mask]\n",
    "    \n",
    "    extra_columns = np.ones((len(ge_genes), extra_neurons), dtype=int)\n",
    "    adjusted_mask_matrix = np.hstack([sub_pdi_ppi_mask_df, extra_columns])\n",
    "    new_mask_matrix = tf.constant(adjusted_mask_matrix, dtype=tf.float32)\n",
    "    \n",
    "    return new_mask_matrix\n",
    "\n",
    "def create_dna_mask_matrix (extra_neurons):\n",
    "    de_gene_to_idx = {gene: i for i, gene in enumerate(dna_genes)}\n",
    "    target_to_idx = {target: j for j, target in enumerate(dna_unique_targets)}\n",
    "    protein2_to_idx = {protein2: k for k, protein2 in enumerate(dna_unique_protein2)}\n",
    "\n",
    "\n",
    "    pdi_mask_matrix = np.zeros((len(dna_genes), len(dna_unique_targets)), dtype=int)\n",
    "\n",
    "\n",
    "    for _, row in df_dna_pdi.iterrows():\n",
    "        tfa = row[\"TF\"]\n",
    "        target = row[\"Target\"]\n",
    "        if tfa in de_gene_to_idx and target in target_to_idx:\n",
    "            tf_idx = de_gene_to_idx[tfa]\n",
    "            target_idx = target_to_idx[target]\n",
    "            pdi_mask_matrix[tf_idx, target_idx] = 1\n",
    "    \n",
    "    ppi_mask_matrix = np.zeros((len(dna_genes), len(dna_unique_protein2)))\n",
    "\n",
    "    for _, row in df_dna_ppi.iterrows():\n",
    "        protein1 = row[\"protein1\"]\n",
    "        protein2 = row[\"protein2\"]\n",
    "        combined_score = row[\"combined_score\"]\n",
    "\n",
    "        if protein1 in de_gene_to_idx and protein2 in protein2_to_idx:\n",
    "            protein1_idx = de_gene_to_idx[protein1]\n",
    "            protein2_idx = protein2_to_idx[protein2]\n",
    "            ppi_mask_matrix[protein1_idx, protein2_idx] = combined_score \n",
    "            \n",
    "    pdi_mask_df=     pd.DataFrame(pdi_mask_matrix)\n",
    "    ppi_mask_df=     pd.DataFrame(ppi_mask_matrix)\n",
    "    pdi_mask_df.columns = dna_unique_targets\n",
    "    ppi_mask_df.columns = dna_unique_protein2\n",
    "    pdi_ppi_mask_df = pd.concat([pdi_mask_df, ppi_mask_df], axis=1)\n",
    "    pdi_ppi_mask_df = pdi_ppi_mask_df.loc[:, ~pdi_ppi_mask_df.columns.duplicated(keep='last')]\n",
    "    col_mask = pdi_ppi_mask_df.columns.isin(dna_pdi_ppi_genept)\n",
    "    sub_pdi_ppi_mask_df = pdi_ppi_mask_df.loc[:, col_mask]\n",
    "\n",
    "    \n",
    "    extra_columns = np.ones((len(dna_genes), extra_neurons), dtype=int)\n",
    "    adjusted_mask_matrix = np.hstack([sub_pdi_ppi_mask_df, extra_columns])\n",
    "    new_mask_matrix = tf.constant(adjusted_mask_matrix, dtype=tf.float32)\n",
    "    \n",
    "    return new_mask_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5161905-ef7c-4943-aa4d-46a2dc84f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_target_to_kegg = pd.read_csv(Path(__file__).parent / \"Dataset\"/\"scTrioseq2\"/ \"ge_target_to_KEGG_significant.csv\",sep=',')\n",
    "dna_target_to_kegg = pd.read_csv(Path(__file__).parent / \"Dataset\"/\"scTrioseq2\"/ \"dna_target_to_KEGG_significant.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235fc5c0-0c09-47c7-aa1a-36d708372be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ge_pathway_mask_matrix ():\n",
    "    genes = ge_pdi_ppi_genept\n",
    "    pathways = ge_target_to_kegg[\"PathwayID\"].unique().tolist()\n",
    "\n",
    "    gene_to_idx = {gene: i for i, gene in enumerate(genes)}\n",
    "    pathway_to_idx = {pw: j for j, pw in enumerate(pathways)}\n",
    "\n",
    "    mask_matrix = np.zeros((len(genes), len(pathways)), dtype=int)\n",
    "\n",
    "    for _, row in ge_target_to_kegg.iterrows():\n",
    "        gene = row[\"SYMBOL\"]\n",
    "        pw = row[\"PathwayID\"]\n",
    "        if gene in gene_to_idx and pw in pathway_to_idx:\n",
    "            i = gene_to_idx[gene]\n",
    "            j = pathway_to_idx[pw]\n",
    "            mask_matrix[i, j] = 1\n",
    "    mask_df = pd.DataFrame(mask_matrix, index=genes, columns=pathways)\n",
    "    return mask_df\n",
    "\n",
    "def create_dna_pathway_mask_matrix ():\n",
    "    genes = dna_pdi_ppi_genept\n",
    "    pathways = dna_target_to_kegg[\"PathwayID\"].unique().tolist()\n",
    "\n",
    "    gene_to_idx = {gene: i for i, gene in enumerate(genes)}\n",
    "    pathway_to_idx = {pw: j for j, pw in enumerate(pathways)}\n",
    "\n",
    "    mask_matrix = np.zeros((len(genes), len(pathways)), dtype=int)\n",
    "\n",
    "    for _, row in dna_target_to_kegg.iterrows():\n",
    "        gene = row[\"SYMBOL\"]\n",
    "        pw = row[\"PathwayID\"]\n",
    "        if gene in gene_to_idx and pw in pathway_to_idx:\n",
    "            i = gene_to_idx[gene]\n",
    "            j = pathway_to_idx[pw]\n",
    "            mask_matrix[i, j] = 1\n",
    "    mask_df = pd.DataFrame(mask_matrix, index=genes, columns=pathways)\n",
    "    return mask_df\n",
    "    \n",
    "mask_gene_pathway  = create_ge_pathway_mask_matrix ()\n",
    "mask_dna_pathway = create_dna_pathway_mask_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe572a-d773-4306-94a1-69ab748f924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLayer(layers.Layer):\n",
    "    def __init__(self, mask_matrix, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mask_matrix = K.constant(mask_matrix, dtype='float32')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return K.dot(inputs, self.mask_matrix)\n",
    "\n",
    "\n",
    "class AttentionPathwayLayer(layers.Layer):\n",
    "    def __init__(self, genept_embs, pathway_mask, init_seed=42, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        genept_np = genept_embs.values if hasattr(genept_embs, \"values\") else np.asarray(genept_embs)\n",
    "        n_genes, D_embed = genept_np.shape\n",
    "\n",
    "        pw_np = pathway_mask.values if hasattr(pathway_mask, \"values\") else np.asarray(pathway_mask)\n",
    "        n_pathways = pw_np.shape[1]\n",
    "\n",
    "        self.G = K.constant(genept_np, dtype=\"float32\")\n",
    "        self.P = K.constant(pw_np, dtype=\"float32\")\n",
    "\n",
    "        glorot = initializers.GlorotUniform(seed=init_seed)\n",
    "        self.W = self.add_weight(\n",
    "            shape=(n_pathways, D_embed),\n",
    "            initializer=glorot,\n",
    "            trainable=True,\n",
    "            name=\"W_query\"\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        G_T      = K.transpose(self.G)            \n",
    "        S        = K.dot(self.W, G_T)             \n",
    "        S_T      = K.transpose(S)                 \n",
    "        S_masked = S_T * self.P                   \n",
    "        alpha    = K.softmax(S_masked, axis=0)    \n",
    "        x_sq     = K.squeeze(x, axis=-1)          \n",
    "        out_mat  = K.dot(x_sq, alpha)             \n",
    "        return K.expand_dims(out_mat, axis=-1)    \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        batch_size, n_genes, _ = input_shape\n",
    "        n_pathways = K.int_shape(self.P)[1]\n",
    "        return (batch_size, n_pathways, 1)\n",
    "    \n",
    "    def get_attention(self):\n",
    "        G_T      = K.transpose(self.G)            \n",
    "        S        = K.dot(self.W, G_T)             \n",
    "        S_T      = K.transpose(S)                 \n",
    "        S_masked = S_T * self.P                   \n",
    "        return K.softmax(S_masked, axis=0)      \n",
    "\n",
    "\n",
    "def create_model(\n",
    "    num_ex_neuron,\n",
    "    layer_one,\n",
    "    activation_function_one,\n",
    "    activation_function_two,\n",
    "    activation_function_three,\n",
    "    dropout_p,\n",
    "    learning_rate,\n",
    "    l2_reg,\n",
    "    optimizer_choice,\n",
    "    genept_gene_emb,\n",
    "    mask_gene_pathway,\n",
    "    genept_dna_emb,\n",
    "    mask_dna_pathway\n",
    "):\n",
    "\n",
    "    new_ge_mask_matrix = create_ge_mask_matrix(num_ex_neuron)\n",
    "    new_dna_mask_matrix = create_dna_mask_matrix(num_ex_neuron)\n",
    "    \n",
    "    inputA = Input(shape=(df_gene.shape[1],), name=\"gene_input\")\n",
    "    x = layers.Dense(\n",
    "        new_ge_mask_matrix.shape[0],\n",
    "        activation=activation_function_one,\n",
    "        kernel_regularizer=regularizers.l2(l2_reg),\n",
    "        kernel_initializer=initializers.LecunUniform(42)\n",
    "    )(inputA)\n",
    "    x = MaskedLayer(new_ge_mask_matrix)(x)\n",
    "    x = Dropout(dropout_p)(x)\n",
    "    x_feat = Lambda(lambda t: K.expand_dims(t, -1), name=\"gene_add_dim\")(x)\n",
    "\n",
    "    gene_path_layer = AttentionPathwayLayer(\n",
    "    genept_embs  = genept_gene_emb,\n",
    "    pathway_mask = mask_gene_pathway,\n",
    "    name         = \"gene_path_attn\"\n",
    "    )\n",
    "    x_path = gene_path_layer(x_feat)\n",
    "    x_path = Flatten()(x_path)\n",
    "\n",
    "    x_proj = layers.Dense(\n",
    "        layer_one,\n",
    "        activation=activation_function_two,\n",
    "        kernel_regularizer=regularizers.l2(l2_reg),\n",
    "        kernel_initializer=initializers.LecunUniform(42),\n",
    "        name=\"gene_proj\"\n",
    "    )(x_path)\n",
    "\n",
    "    inputB = Input(shape=(df_dna.shape[1],), name=\"dna_input\")\n",
    "    y = layers.Dense(\n",
    "        new_dna_mask_matrix.shape[0],\n",
    "        activation=activation_function_one,\n",
    "        kernel_regularizer=regularizers.l2(l2_reg),\n",
    "        kernel_initializer=initializers.LecunUniform(42)\n",
    "    )(inputB)\n",
    "    y = MaskedLayer(new_dna_mask_matrix)(y)\n",
    "    y = Dropout(dropout_p)(y)\n",
    "    y_feat = Lambda(lambda t: K.expand_dims(t, -1), name=\"dna_add_dim\")(y)\n",
    "\n",
    "    dna_path_layer = AttentionPathwayLayer(\n",
    "    genept_embs  = genept_dna_emb,\n",
    "    pathway_mask = mask_dna_pathway,\n",
    "    name         = \"dna_path_attn\"\n",
    "    )\n",
    "    y_path = dna_path_layer(y_feat)\n",
    "    y_path = Flatten()(y_path)\n",
    "\n",
    "    y_proj = layers.Dense(\n",
    "        layer_one,\n",
    "        activation=activation_function_two,\n",
    "        kernel_regularizer=regularizers.l2(l2_reg),\n",
    "        kernel_initializer=initializers.LecunUniform(42),\n",
    "        name=\"dna_proj\"\n",
    "    )(y_path)\n",
    "\n",
    "    merged = concatenate([x_proj, y_proj], name=\"merge_xy\")\n",
    "    h = layers.Dense(\n",
    "        12,\n",
    "        activation=activation_function_three,\n",
    "        kernel_regularizer=regularizers.l2(l2_reg),\n",
    "        kernel_initializer=initializers.GlorotUniform(42),\n",
    "        name=\"fusion_dense\"\n",
    "    )(merged)\n",
    "    h = Dropout(dropout_p, name=\"drop_fusion\")(h)\n",
    "    out = layers.Dense(\n",
    "        4,\n",
    "        activation=\"softmax\",\n",
    "        kernel_regularizer=regularizers.l2(l2_reg),\n",
    "        kernel_initializer=initializers.GlorotUniform(42),\n",
    "        name=\"output\"\n",
    "    )(h)\n",
    "\n",
    "    model = Model(inputs=[inputA, inputB], outputs=out, name=\"PathwayModel\")\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89b57c-5f26-4b58-be38-7d4c797d4c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_cv(X_train, X_val, y_train, y_val, params):\n",
    "    model = create_model(\n",
    "        num_ex_neuron=params['num_ex_neuron'],\n",
    "        layer_one=params['layer_one'],\n",
    "        activation_function_one=params['activation_function_one'],\n",
    "        activation_function_two=params['activation_function_two'],\n",
    "        activation_function_three=params['activation_function_three'],\n",
    "        dropout_p=params['dropout_p'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        l2_reg=params['l2_reg'],\n",
    "        optimizer_choice=params['optimizer'],\n",
    "        genept_gene_emb       = genept_gene_emb,\n",
    "        mask_gene_pathway     = mask_gene_pathway,\n",
    "        genept_dna_emb        = genept_dna_emb,\n",
    "        mask_dna_pathway      = mask_dna_pathway\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=params['epoch'],\n",
    "        batch_size=params['batch_size'],\n",
    "        shuffle = False,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_val).argmax(1)\n",
    "    \n",
    "\n",
    "    f1_weighted = f1_score(y_val, y_pred, average='weighted')\n",
    "    f1_macro = f1_score(y_val, y_pred, average='macro')\n",
    "    f1_micro = f1_score(y_val, y_pred, average='micro')\n",
    "\n",
    "    precision_weighted = precision_score(y_val, y_pred, average='weighted')\n",
    "    precision_macro = precision_score(y_val, y_pred, average='macro')\n",
    "    precision_micro = precision_score(y_val, y_pred, average='micro')\n",
    "    \n",
    "\n",
    "    recall_weighted = recall_score(y_val, y_pred, average='weighted')\n",
    "    recall_macro = recall_score(y_val, y_pred, average='macro')\n",
    "    recall_micro = recall_score(y_val, y_pred, average='micro')\n",
    "    \n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    return {\n",
    "        'history': history.history,\n",
    "        'f1_weighted': f1_weighted,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "        'precision_weighted': precision_weighted,\n",
    "        'precision_macro': precision_macro,\n",
    "        'precision_micro': precision_micro,\n",
    "        'recall_weighted': recall_weighted,\n",
    "        'recall_macro': recall_macro,\n",
    "        'recall_micro': recall_micro,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "def evaluate_combination(param_combination,X_gene_train,X_dna_train,y_train,n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    f1_weighted_list = []\n",
    "    f1_macro_list = []\n",
    "    f1_micro_list = []\n",
    "    \n",
    "    precision_weighted_list = []\n",
    "    precision_macro_list = []\n",
    "    precision_micro_list = []\n",
    "    \n",
    "    recall_weighted_list = []\n",
    "    recall_macro_list = []\n",
    "    recall_micro_list = []\n",
    "    \n",
    "    accuracy_list = []\n",
    "    all_histories = []\n",
    "    \n",
    "    for train_idx, val_idx in skf.split(X_gene_train, y_train):\n",
    "        Xg_tr, Xg_val = X_gene_train[train_idx], X_gene_train[val_idx]\n",
    "        Xd_tr, Xd_val = X_dna_train[train_idx], X_dna_train[val_idx]\n",
    "        y_tr, y_val   = y_train[train_idx], y_train[val_idx]\n",
    "    \n",
    "        scores = evaluate_model_cv([Xg_tr, Xd_tr], [Xg_val, Xd_val], y_tr, y_val, param_combination)\n",
    "        \n",
    "        history_dict = scores.pop('history')\n",
    "        all_histories.append(history_dict)\n",
    "        \n",
    "        f1_weighted_list.append(scores['f1_weighted'])\n",
    "        f1_macro_list.append(scores['f1_macro'])\n",
    "        f1_micro_list.append(scores['f1_micro'])\n",
    "        \n",
    "        precision_weighted_list.append(scores['precision_weighted'])\n",
    "        precision_macro_list.append(scores['precision_macro'])\n",
    "        precision_micro_list.append(scores['precision_micro'])\n",
    "        \n",
    "        recall_weighted_list.append(scores['recall_weighted'])\n",
    "        recall_macro_list.append(scores['recall_macro'])\n",
    "        recall_micro_list.append(scores['recall_micro'])\n",
    "        \n",
    "        accuracy_list.append(scores['accuracy'])\n",
    "    \n",
    "    results = {\n",
    "        'f1_weighted_mean': np.mean(f1_weighted_list),\n",
    "        'f1_weighted_std': np.std(f1_weighted_list),\n",
    "        'f1_macro_mean': np.mean(f1_macro_list),\n",
    "        'f1_macro_std': np.std(f1_macro_list),\n",
    "        'f1_micro_mean': np.mean(f1_micro_list),\n",
    "        'f1_micro_std': np.std(f1_micro_list),\n",
    "        'precision_weighted_mean': np.mean(precision_weighted_list),\n",
    "        'precision_weighted_std': np.std(precision_weighted_list),\n",
    "        'precision_macro_mean': np.mean(precision_macro_list),\n",
    "        'precision_macro_std': np.std(precision_macro_list),\n",
    "        'precision_micro_mean': np.mean(precision_micro_list),\n",
    "        'precision_micro_std': np.std(precision_micro_list),\n",
    "        'recall_weighted_mean': np.mean(recall_weighted_list),\n",
    "        'recall_weighted_std': np.std(recall_weighted_list),\n",
    "        'recall_macro_mean': np.mean(recall_macro_list),\n",
    "        'recall_macro_std': np.std(recall_macro_list),\n",
    "        'recall_micro_mean': np.mean(recall_micro_list),\n",
    "        'recall_micro_std': np.std(recall_micro_list),\n",
    "        'accuracy_mean': np.mean(accuracy_list),\n",
    "        'accuracy_std': np.std(accuracy_list)\n",
    "    }\n",
    "    \n",
    "    return param_combination, results, all_histories\n",
    "\n",
    "\n",
    "params_grid = {\n",
    "     'num_ex_neuron': [0],\n",
    "     'layer_one': [64],\n",
    "     'activation_function_one': ['relu'],\n",
    "     'activation_function_two': ['sigmoid'],\n",
    "     'activation_function_three': ['tanh'],\n",
    "     'dropout_p': [0.3],\n",
    "     'learning_rate': [0.01],\n",
    "    'l2_reg': [0.01],\n",
    "    'epoch': [200],\n",
    "    'batch_size':[16],\n",
    "    'optimizer': ['sgd']\n",
    " }\n",
    "\n",
    "param_combinations = list(itertools.product(\n",
    "    params_grid['num_ex_neuron'],\n",
    "    params_grid['layer_one'],\n",
    "    params_grid['activation_function_one'],\n",
    "    params_grid['activation_function_two'],\n",
    "    params_grid['activation_function_three'],\n",
    "    params_grid['dropout_p'],\n",
    "    params_grid['learning_rate'],\n",
    "    params_grid['l2_reg'],\n",
    "    params_grid['epoch'],\n",
    "    params_grid['batch_size'],\n",
    "    params_grid['optimizer']\n",
    "    \n",
    "))\n",
    "\n",
    "\n",
    "param_dicts = []\n",
    "for comb in param_combinations:\n",
    "    param_dicts.append({\n",
    "        'num_ex_neuron': comb[0],\n",
    "        'layer_one': comb[1],\n",
    "        'activation_function_one': comb[2],\n",
    "        'activation_function_two': comb[3],\n",
    "        'activation_function_three': comb[4],\n",
    "        'dropout_p': comb[5],\n",
    "        'learning_rate': comb[6],\n",
    "        'l2_reg': comb[7],\n",
    "        'epoch': comb[8],\n",
    "        'batch_size': comb[9],\n",
    "        'optimizer': comb[10]\n",
    "    })\n",
    "\n",
    "\n",
    "X_gene_train, X_gene_test, X_dna_train, X_dna_test, y_train, y_test = train_test_split(df_gene, df_dna, y, test_size=0.2, stratify=y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_gene_train=(np.array(X_gene_train).astype(np.float32))\n",
    "scaler.fit(X_gene_train)\n",
    "X_gene_train=scaler.transform(X_gene_train)\n",
    "\n",
    "X_gene_test=(np.array(X_gene_test).astype(np.float32))\n",
    "scaler.fit(X_gene_test)\n",
    "X_gene_test=scaler.transform(X_gene_test)\n",
    "\n",
    "X_dna_train=(np.array(X_dna_train).astype(np.float32))\n",
    "scaler.fit(X_dna_train)\n",
    "X_dna_train=scaler.transform(X_dna_train)\n",
    "\n",
    "X_dna_test=(np.array(X_dna_test).astype(np.float32))\n",
    "scaler.fit(X_dna_test)\n",
    "X_dna_test=scaler.transform(X_dna_test)\n",
    "\n",
    "with tqdm_joblib(\n",
    "        tqdm(desc=\"Evaluating hyperparameter combinations\",\n",
    "             total=len(param_dicts))\n",
    "     ) as progress_bar:\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(evaluate_combination)(\n",
    "            param, X_gene_train, X_dna_train, y_train, n_splits=5\n",
    "        )\n",
    "        for param in param_dicts\n",
    "    )\n",
    "\n",
    "results_list = []\n",
    "histories_dict = {}\n",
    "best_param_weighted = None\n",
    "best_weighted_scores = None\n",
    "best_avg_f1_weighted = -np.inf\n",
    "\n",
    "best_param_macro = None\n",
    "best_macro_scores = None\n",
    "best_avg_f1_macro = -np.inf\n",
    "\n",
    "best_param_micro = None\n",
    "best_micro_scores = None\n",
    "best_avg_f1_micro = -np.inf\n",
    "\n",
    "for param_dict, scores_dict, histories in results:\n",
    "    key = str(param_dict)\n",
    "    histories_dict[key] = histories\n",
    "\n",
    "    row = {}\n",
    "    row.update(param_dict)\n",
    "    row.update(scores_dict)\n",
    "    results_list.append(row)\n",
    "\n",
    "    if scores_dict['f1_weighted_mean'] > best_avg_f1_weighted:\n",
    "        best_avg_f1_weighted = scores_dict['f1_weighted_mean']\n",
    "        best_param_weighted  = param_dict\n",
    "        best_weighted_scores = scores_dict\n",
    "\n",
    "    if scores_dict['f1_macro_mean'] > best_avg_f1_macro:\n",
    "        best_avg_f1_macro = scores_dict['f1_macro_mean']\n",
    "        best_param_macro  = param_dict\n",
    "        best_macro_scores = scores_dict\n",
    "\n",
    "    if scores_dict['f1_micro_mean'] > best_avg_f1_micro:\n",
    "        best_avg_f1_micro = scores_dict['f1_micro_mean']\n",
    "        best_param_micro  = param_dict\n",
    "        best_micro_scores = scores_dict\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "best_key = str(best_param_macro)\n",
    "best_histories = histories_dict[best_key]  \n",
    "\n",
    "\n",
    "hyperparam_cols = list(param_dict.keys())\n",
    "\n",
    "\n",
    "weighted_cols = hyperparam_cols + ['f1_weighted_mean', 'f1_weighted_std',\n",
    "                                     'precision_weighted_mean', 'precision_weighted_std',\n",
    "                                     'recall_weighted_mean', 'recall_weighted_std',\n",
    "                                     'accuracy_mean', 'accuracy_std']\n",
    "results_df_weighted = results_df[weighted_cols]\n",
    "\n",
    "macro_cols = hyperparam_cols + ['f1_macro_mean', 'f1_macro_std',\n",
    "                                  'precision_macro_mean', 'precision_macro_std',\n",
    "                                  'recall_macro_mean', 'recall_macro_std',\n",
    "                                  'accuracy_mean', 'accuracy_std']\n",
    "results_df_macro = results_df[macro_cols]\n",
    "\n",
    "micro_cols = hyperparam_cols + ['f1_micro_mean', 'f1_micro_std',\n",
    "                                  'precision_micro_mean', 'precision_micro_std',\n",
    "                                  'recall_micro_mean', 'recall_micro_std',\n",
    "                                  'accuracy_mean', 'accuracy_std']\n",
    "results_df_micro = results_df[micro_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576c647-0fa9-44ff-b26b-b152a8f96389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_test(\n",
    "    num_ex_neuron,\n",
    "    layer_one,\n",
    "    activation_function_one,\n",
    "    activation_function_two,\n",
    "    activation_function_three,\n",
    "    dropout_p,\n",
    "    learning_rate,\n",
    "    l2_reg,\n",
    "    optimizer_choice\n",
    "):\n",
    "\n",
    "    new_ge_mask_matrix = create_ge_mask_matrix(num_ex_neuron)    \n",
    "    new_dna_mask_matrix = create_dna_mask_matrix(num_ex_neuron)  \n",
    "\n",
    "    inputA = Input(shape=(df_gene.shape[1],), name=\"gene_input\") \n",
    "    inputB = Input(shape=(df_dna.shape[1],), name=\"dna_input\")   \n",
    "\n",
    "    x1 = layers.Dense(\n",
    "        new_ge_mask_matrix.shape[0],               \n",
    "        kernel_initializer=LecunUniform(seed=42),\n",
    "        activation=activation_function_one,\n",
    "        kernel_regularizer=l2(l2_reg)\n",
    "    )(inputA)                                        \n",
    "\n",
    "\n",
    "    x1_masked = MaskedLayer(new_ge_mask_matrix)(x1) \n",
    "    x1_masked = Dropout(dropout_p)(x1_masked)       \n",
    "\n",
    "    x1_feat = layers.Lambda(lambda t: K.expand_dims(t, -1), name=\"gene_add_dim\")(x1_masked)\n",
    "\n",
    "    gene_path_layer = AttentionPathwayLayer(\n",
    "        genept_embs  = genept_gene_emb,    \n",
    "        pathway_mask = mask_gene_pathway,  \n",
    "        name         = \"gene_path_attn\"\n",
    "    )\n",
    "    x1_path = gene_path_layer(x1_feat)     \n",
    "\n",
    "    x1_path = Flatten(name=\"gene_flat_path\")(x1_path)  \n",
    "\n",
    "    x1_proj = layers.Dense(\n",
    "        layer_one,\n",
    "        kernel_initializer=LecunUniform(seed=42),\n",
    "        activation=activation_function_two,\n",
    "        kernel_regularizer=l2(l2_reg),\n",
    "        name=\"gene_proj\"\n",
    "    )(x1_path)                                   \n",
    "\n",
    "    y1 = layers.Dense(\n",
    "        new_dna_mask_matrix.shape[0],               \n",
    "        kernel_initializer=LecunUniform(seed=42),\n",
    "        activation=activation_function_one,\n",
    "        kernel_regularizer=l2(l2_reg)\n",
    "    )(inputB)                                     \n",
    "\n",
    "    y1_masked = MaskedLayer(new_dna_mask_matrix)(y1)  \n",
    "    y1_masked = Dropout(dropout_p)(y1_masked)         \n",
    "\n",
    "    y1_feat = layers.Lambda(lambda t: K.expand_dims(t, -1), name=\"dna_add_dim\")(y1_masked)\n",
    "\n",
    "    dna_path_layer = AttentionPathwayLayer(\n",
    "        genept_embs  = genept_dna_emb,      \n",
    "        pathway_mask = mask_dna_pathway,    \n",
    "        name         = \"dna_path_attn\"\n",
    "    )\n",
    "    y1_path = dna_path_layer(y1_feat) \n",
    "    y1_path = Flatten(name=\"dna_flat_path\")(y1_path)   \n",
    "\n",
    "    y1_proj = layers.Dense(\n",
    "        layer_one,\n",
    "        kernel_initializer=LecunUniform(seed=42),\n",
    "        activation=activation_function_two,\n",
    "        kernel_regularizer=l2(l2_reg),\n",
    "        name=\"dna_proj\"\n",
    "    )(y1_path)                                    \n",
    "\n",
    "    merged = concatenate([x1_proj, y1_proj], name=\"merge_xy\")  \n",
    "\n",
    "    h = layers.Dense(\n",
    "        12,\n",
    "        activation=activation_function_three,\n",
    "        kernel_initializer=GlorotUniform(seed=42),\n",
    "        kernel_regularizer=l2(l2_reg),\n",
    "        name=\"fusion_dense\"\n",
    "    )(merged)                                        \n",
    "    h = Dropout(dropout_p, name=\"drop_fusion\")(h)    \n",
    "\n",
    "    outputs = layers.Dense(\n",
    "        4,\n",
    "        activation=\"softmax\",\n",
    "        kernel_initializer=GlorotUniform(seed=42),\n",
    "        kernel_regularizer=l2(l2_reg),\n",
    "        name=\"output\"\n",
    "    )(h)                                             \n",
    "\n",
    "    model = Model(inputs=[inputA, inputB], outputs=outputs, name=\"PathwayModel_Test\")\n",
    "\n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda02d6-b3bd-4028-ba48-b0095d80245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test_model(best_param, avg_type, save_csv_path=None):\n",
    "   \n",
    "    per_run_results = []\n",
    "\n",
    "    for run_i in range(1,11):\n",
    "       \n",
    "        model = create_model_test(\n",
    "            num_ex_neuron           = best_param['num_ex_neuron'],\n",
    "            layer_one               = best_param['layer_one'],\n",
    "            activation_function_one = best_param['activation_function_one'],\n",
    "            activation_function_two = best_param['activation_function_two'],\n",
    "            activation_function_three = best_param['activation_function_three'],\n",
    "            dropout_p               = best_param['dropout_p'],\n",
    "            learning_rate           = best_param['learning_rate'],\n",
    "            l2_reg                  = best_param['l2_reg'],\n",
    "            optimizer_choice        = best_param['optimizer']\n",
    "        )\n",
    "        model.fit(\n",
    "            [X_gene_train, X_dna_train],\n",
    "            y_train,\n",
    "            epochs=best_param['epoch'],\n",
    "            batch_size=best_param['batch_size'],\n",
    "            shuffle=False,\n",
    "            verbose=0\n",
    "        )\n",
    "        y_pred = model.predict([X_gene_test, X_dna_test]).argmax(axis=1)\n",
    "\n",
    "        f1_val      = f1_score(y_test, y_pred, average=avg_type)\n",
    "        precision_v = precision_score(y_test, y_pred, average=avg_type)\n",
    "        recall_v    = recall_score(y_test, y_pred, average=avg_type)\n",
    "        acc_v       = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        per_run_results.append({\n",
    "            'run_idx': run_i,\n",
    "            f'f1_{avg_type}':       f1_val,\n",
    "            f'precision_{avg_type}': precision_v,\n",
    "            f'recall_{avg_type}':    recall_v,\n",
    "            'accuracy':              acc_v\n",
    "        })\n",
    "\n",
    "    df_runs = pd.DataFrame(per_run_results)\n",
    "    summary = {\n",
    "        f'f1_{avg_type}_mean':        df_runs[f'f1_{avg_type}'].mean(),\n",
    "        f'f1_{avg_type}_std':         df_runs[f'f1_{avg_type}'].std(),\n",
    "        f'precision_{avg_type}_mean': df_runs[f'precision_{avg_type}'].mean(),\n",
    "        f'precision_{avg_type}_std':  df_runs[f'precision_{avg_type}'].std(),\n",
    "        f'recall_{avg_type}_mean':    df_runs[f'recall_{avg_type}'].mean(),\n",
    "        f'recall_{avg_type}_std':     df_runs[f'recall_{avg_type}'].std(),\n",
    "        'accuracy_mean':              df_runs['accuracy'].mean(),\n",
    "        'accuracy_std':               df_runs['accuracy'].std()\n",
    "    }\n",
    "\n",
    "    df_runs[f'f1_{avg_type}_std']        = pd.NA\n",
    "    df_runs[f'precision_{avg_type}_std'] = pd.NA\n",
    "    df_runs[f'recall_{avg_type}_std']    = pd.NA\n",
    "    df_runs['accuracy_std']              = pd.NA\n",
    "\n",
    "    summary_row = {\n",
    "        'run_idx': 'mean',\n",
    "        f'f1_{avg_type}':        summary[f'f1_{avg_type}_mean'],\n",
    "        f'f1_{avg_type}_std':    summary[f'f1_{avg_type}_std'],\n",
    "        f'precision_{avg_type}': summary[f'precision_{avg_type}_mean'],\n",
    "        f'precision_{avg_type}_std': summary[f'precision_{avg_type}_std'],\n",
    "        f'recall_{avg_type}':    summary[f'recall_{avg_type}_mean'],\n",
    "        f'recall_{avg_type}_std': summary[f'recall_{avg_type}_std'],\n",
    "        'accuracy':              summary['accuracy_mean'],\n",
    "        'accuracy_std':          summary['accuracy_std']\n",
    "    }\n",
    "    df_summary = pd.DataFrame([summary_row])\n",
    "\n",
    "    df_runs = pd.concat([df_runs, df_summary], ignore_index=True)\n",
    "\n",
    "    if save_csv_path is not None:\n",
    "        df_runs.to_csv(save_csv_path, index=False)\n",
    "\n",
    "    return summary, df_runs\n",
    "\n",
    "summary_macro, df_macro_runs = evaluate_test_model(\n",
    "    best_param_macro,\n",
    "    avg_type=\"macro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colo2",
   "language": "python",
   "name": "colo2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
